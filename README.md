
---

## âš™ï¸ Requirements

- Python 3.10+
- Ollama installed and running
- OS: Windows / Linux / macOS

---

## ğŸ“¦ Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone <your-repo-url>
cd app
2ï¸âƒ£ Create and activate virtual environment (optional but recommended)
bash
Copy code
python -m venv venv
venv\Scripts\activate   # Windows
3ï¸âƒ£ Install dependencies
bash
Copy code
pip install -r requirements.txt
ğŸ¤– Setup Ollama
Install Ollama
ğŸ‘‰ https://ollama.com/

Pull the model
bash
Copy code
ollama pull llama3.2:1b
Start Ollama server
bash
Copy code
ollama serve
ğŸ“„ Add PDFs for RAG
Place your PDF files inside:

kotlin
Copy code
D:\app\data\pdfs\
Example:

Copy code
s41598-024-71118-7.pdf
These documents will be chunked, embedded, and indexed automatically.

â–¶ï¸ Run the Application
Start FastAPI server (from project root)
powershell
Copy code
D:
cd D:\app
python -m uvicorn app.main:app --reload
You should see:

nginx
Copy code
Uvicorn running on http://127.0.0.1:8000
ğŸŒ Access the Application
API Documentation
arduino
Copy code
http://127.0.0.1:8000/docs
Web UI
Open directly:

makefile
Copy code
D:\app\ui\index.html
OR (if served via FastAPI):

cpp
Copy code
http://127.0.0.1:8000/
ğŸ§ª Example API Request
json
Copy code
POST /chat
{
  "session_id": "user1",
  "query": "What is CTNet?"
}
Example Response
json
Copy code
{
  "answer": "CTNet is a convolutional neural network architecture designed for..."
}
ğŸ§  Context Awareness
Each session_id maintains its own conversation history

LangGraph manages state transitions

Past messages influence future responses

Retrieved PDF context is injected dynamically

ğŸ›¡ï¸ Notes & Limitations
In-memory session storage (resets on server restart)

Designed for local development and demos

Can be extended with:

Redis / DB for persistence

Authentication

